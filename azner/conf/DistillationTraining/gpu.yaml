seed: 42
cudnn:
  deterministic: True
  benchmark: False
monitoring:
  monitor: entity_f1
  mode: max
training_params:
  max_epochs: 10
save_dir: ???
model:
  _target_: azner.modelling.distillation.models.SequenceTaggingTaskSpecificDistillation
  data_dir: ???
  label_list:
    - B-disease
    - B-drug
    - B-gene
    - B-mutation
    - B-species
    - I-disease
    - I-drug
    - I-gene
    - I-mutation
    - I-species
    - O
  student_model_path: ???
  teacher_model_path: ???
  batch_size: 8
  num_workers: 2
  temperature: 1.0
  warmup_steps: 0
  learning_rate: 5e-5
  schedule: torchStepLR
  weight_decay: 0.01
  accumulate_grad_batches: ${DistillationTraining.trainer.accumulate_grad_batches}
  max_epochs: ${DistillationTraining.training_params.max_epochs}
trainer:
  _target_: pytorch_lightning.Trainer
  progress_bar_refresh_rate: 1
  num_sanity_val_steps: 2
  gpus: 0
  accelerator: ~
  val_check_interval: 1.0
  accumulate_grad_batches: 1
  max_epochs: ${DistillationTraining.training_params.max_epochs}
  plugins:
    - _target_: azner.modelling.distillation.lightning_plugins.StudentModelCheckpointIO
      model_name_or_path: ${DistillationTraining.model.student_model_path}
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: ${DistillationTraining.save_dir}
      filename: "student_model-{epoch:02d}-{valF1:.4f}-{validation_loss_epoch:.3f}-{step:05d}"
      monitor: ${DistillationTraining.monitoring.monitor}
      mode: ${DistillationTraining.monitoring.mode}
      save_top_k: 5
      save_last: True
      every_n_train_steps: ~
      every_n_epochs: ~
    - _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
      monitor: ${DistillationTraining.monitoring.monitor}
      mode: ${DistillationTraining.monitoring.mode}
      min_delta: 0.00
      patience: 5
      verbose: True