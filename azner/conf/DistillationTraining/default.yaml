seed: 42
trainer:
  _target_: pytorch_lightning.Trainer
  progress_bar_refresh_rate: -1
  num_sanity_val_steps: 2
  gpus: 0
  accelerator: ddp
  val_check_interval: 1.0
  accumulate_grad_batches: 1
  max_epochs: 10
  num_nodes: ~

  plugins:
    - _target_: azner.modelling.distillation.distillation.custom_checkpoint.StudentModelCheckpointIO
      model_name_or_path: ???
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: ???
      filename: "student_model-{epoch:02d}-{valF1:.4f}-{validation_loss_epoch:.3f}-{step:05d}"
      metric: entity_f1
      mode: max
      save_top_k: 5
      save_last: True
      every_n_train_steps: ~
      every_n_epochs: ~
    - _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
      monitor: entity_f1
      mode: max
      min_delta: 0.00
      patience: 5
      verbose: True

model:
  _target_: azner.modelling.distillation.distillation.models.SequenceTaggingTaskSpecificDistillation
  data_dir: ???
  label_list:
    - B-disease
    - B-drug
    - B-gene
    - B-mutation
    - B-species
    - I-disease
    - I-drug
    - I-gene
    - I-mutation
    - I-species
    - O
  student_model_path: ???
  teacher_model_path: ???
  batch_size: 32
  num_workers: 2
  temperature: 1.0
  warmup_steps: ~
  learning_rate: 5e-5
  schedule: warmup_linear
  weight_decay: 0.01
  accumulate_grad_batches: ${trainer.accumulate_grad_batches}

