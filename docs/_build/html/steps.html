
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>String Preprocessing &#8212; Kazu  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="TBA" href="training.html" />
    <link rel="prev" title="Kazu data model" href="datamodel.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="training.html" title="TBA"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="datamodel.html" title="Kazu data model"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Kazu  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">String Preprocessing</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="string-preprocessing">
<h1>String Preprocessing<a class="headerlink" href="#string-preprocessing" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="kazu.steps.StringPreprocessorStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kazu.steps.</span></span><span class="sig-name descname"><span class="pre">StringPreprocessorStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.StringPreprocessorStep" title="Permalink to this definition">¶</a></dt>
<dd><p>String Preprocessing steps (subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">kazu.steps.string_preprocessing.StringPreprocessorStep</span></code> are a
special class of step that involves destructive string preprocessing. For instance, you may want to expand
abbreviations before running an NER step.</p>
<p>Implementations will modify the return value of <code class="xref py py-meth docutils literal notranslate"><span class="pre">kazu.data.data.Section.get_text()</span></code>. The
idea is that implementations of these will perform any required string preprocessing before the section text is
passed to another <code class="xref py py-class docutils literal notranslate"><span class="pre">kazu.steps.base.step.Step</span></code>.  Implementations of this step update the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">kazu.data.data.Section.offset_map</span></code>, so that offsets for objects generated by subsequent steps can be
traced back to the original string.</p>
<p>simple implementations need only override create_modifications.</p>
</dd></dl>

<section id="current-implementations-of-stringpreprocessorstep">
<h2>Current implementations of StringPreprocessorStep<a class="headerlink" href="#current-implementations-of-stringpreprocessorstep" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="kazu.steps.SciSpacyAbbreviationExpansionStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kazu.steps.</span></span><span class="sig-name descname"><span class="pre">SciSpacyAbbreviationExpansionStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.SciSpacyAbbreviationExpansionStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Detects abbreviations using the algorithm in “A simple algorithm for identifying
abbreviation definitions in biomedical text.”, (Schwartz &amp; Hearst, 2003).
Uses a modified version of the scispacy abbreviation finder rules, to expand abbreviations. In this implementation,
it’s possible to apply abbreviations across the multiple sections in a <code class="xref py py-class docutils literal notranslate"><span class="pre">kazu.data.data.Document</span></code>.
For instance, abbreviations learnt in an abstract will also be applied throughout the body of the text</p>
</dd></dl>

</section>
</section>
<section id="ner">
<h1>NER<a class="headerlink" href="#ner" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kazu.steps.</span></span><span class="sig-name descname"><span class="pre">TransformersModelForTokenClassificationNerStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detect_subspans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_splitter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">NonContiguousEntitySplitter</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep" title="Permalink to this definition">¶</a></dt>
<dd><p>An wrapper for <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.AutoModelForTokenClassification'.</span> <span class="pre">This</span> <span class="pre">implementation</span> <span class="pre">uses</span> <span class="pre">a</span> <span class="pre">sliding</span>
<span class="pre">window</span> <span class="pre">concept</span> <span class="pre">to</span> <span class="pre">process</span> <span class="pre">large</span> <span class="pre">documents</span> <span class="pre">that</span> <span class="pre">don't</span> <span class="pre">fit</span> <span class="pre">into</span> <span class="pre">the</span> <span class="pre">maximum</span> <span class="pre">sequence</span> <span class="pre">length</span> <span class="pre">allowed</span> <span class="pre">by</span> <span class="pre">a</span> <span class="pre">model.</span>
<span class="pre">Resulting</span> <span class="pre">token</span> <span class="pre">labels</span> <span class="pre">are</span> <span class="pre">then</span> <span class="pre">post</span> <span class="pre">processed</span> <span class="pre">by</span>
<span class="pre">:py:class:`kazu.steps.ner.tokenized_word_processor.TokenizedWordProcessor</span></code>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detect_subspans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_splitter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">NonContiguousEntitySplitter</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – path to HF model, config and tokenizer. Passed to HF .from_pretrained()</p></li>
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>batch_size</strong> – batch size for dataloader</p></li>
<li><p><strong>stride</strong> – passed to HF tokenizers (for splitting long docs)</p></li>
<li><p><strong>max_sequence_length</strong> – passed to HF tokenizers (for splitting long docs)</p></li>
<li><p><strong>trainer</strong> – an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">pytorch_lightning.Trainer</span></code></p></li>
<li><p><strong>threshold</strong> – EXPERIMENTAL the confidence threshold used to detect nested entities</p></li>
<li><p><strong>entity_splitter</strong> – instance of NonContiguousEntitySplitter to detect non-contiguous entities</p></li>
</ul>
</dd>
<dt class="field-even">Param<span class="colon">:</span></dt>
<dd class="field-even"><p>detect_subspans: EXPERIMENTAL attempt to detect nested entities (threshold must be configured)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep.frame_to_tok_word">
<span class="sig-name descname"><span class="pre">frame_to_tok_word</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BatchEncoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_frames</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">section_frame_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">TokenizedWord</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep.frame_to_tok_word" title="Permalink to this definition">¶</a></dt>
<dd><p>depending on the number of frames generated by a string of text, and whether it is the first or last frame,
we need to return different subsets of the frame offsets and frame word_ids
:param batch_encoding: a HF BatchEncoding
:param number_of_frames: number of frames created by the tokenizer for the string
:param frame_index: the index of the query frame, relative to the total number of frames
:param section_frame_index: the index of the section frame, relative to the whole BatchEncoding
:return: Tuple of 2 lists: frame offsets and frame word ids</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep.get_dataloader">
<span class="sig-name descname"><span class="pre">get_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">docs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Document</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Section</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep.get_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>get a dataloader from a List of Document. Collation is handled via DataCollatorWithPadding</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>docs</strong> – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a tuple of dataloader, and a dict of int:Section. The int maps to overflow_to_sample_mapping in the
underlying batch encoding, allowing the processing of docs longer than can fit within the maximum
sequence length of a transformer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep.get_list_of_batch_encoding_frames_for_section">
<span class="sig-name descname"><span class="pre">get_list_of_batch_encoding_frames_for_section</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BatchEncoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">section_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep.get_list_of_batch_encoding_frames_for_section" title="Permalink to this definition">¶</a></dt>
<dd><p>for a given dataloader with a HFDataset, return a list of frame indexes associated with a given section index
:param loader:
:param section_index:
:return:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.TransformersModelForTokenClassificationNerStep.get_softmax_predictions">
<span class="sig-name descname"><span class="pre">get_softmax_predictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#kazu.steps.TransformersModelForTokenClassificationNerStep.get_softmax_predictions" title="Permalink to this definition">¶</a></dt>
<dd><p>get a namedtuple_values_indices consisting of confidence and labels for a given dataloader (i.e. run bert)
:param loader:
:return:</p>
</dd></dl>

</dd></dl>

</section>
<section id="linking">
<h1>Linking<a class="headerlink" href="#linking" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="kazu.steps.SapBertForEntityLinkingStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kazu.steps.</span></span><span class="sig-name descname"><span class="pre">SapBertForEntityLinkingStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apidocs.html#kazu.utils.link_index.EmbeddingIndex" title="kazu.utils.link_index.EmbeddingIndex"><span class="pre">EmbeddingIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PLSapbertModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_string_length_to_trigger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_high_conf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_cutoffs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(99.994,</span> <span class="pre">99.995)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.SapBertForEntityLinkingStep" title="Permalink to this definition">¶</a></dt>
<dd><p>This step wraps Sapbert: Self Alignment pretraining for biomedical entity representation.
We make use of two caches here:
1) <code class="xref py py-class docutils literal notranslate"><span class="pre">kazu.utils.caching.CachedIndexGroup</span></code> Since we need to calculate embeddings for all labels in an ontology
, it makes sense to precompute them once and reload them each time. This is done automatically if no cache file is
detected.
2) <a class="reference internal" href="apidocs.html#kazu.utils.caching.EntityLinkingLookupCache" title="kazu.utils.caching.EntityLinkingLookupCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">kazu.utils.caching.EntityLinkingLookupCache</span></code></a> Since certain entities will come up more frequently, we
cache the result mappings rather than call bert repeatedly.</p>
<p>Original paper <a class="reference external" href="https://aclanthology.org/2021.naacl-main.334.pdf">https://aclanthology.org/2021.naacl-main.334.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.SapBertForEntityLinkingStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apidocs.html#kazu.utils.link_index.EmbeddingIndex" title="kazu.utils.link_index.EmbeddingIndex"><span class="pre">EmbeddingIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PLSapbertModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_string_length_to_trigger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_high_conf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_cutoffs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(99.994,</span> <span class="pre">99.995)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.SapBertForEntityLinkingStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>indices</strong> – list of EmbeddingIndex to use with this model</p></li>
<li><p><strong>embedding_model</strong> – The SapBERT model to use to generate embeddings for entity mentions in input documents</p></li>
<li><p><strong>trainer</strong> – PL trainer to call when generating embeddings</p></li>
<li><p><strong>entity_class_to_ontology_mappings</strong> – defines which NER classes shold be linked to which ontologies</p></li>
<li><p><strong>min_string_length_to_trigger</strong> – a per entity class mapping that signals sapbert will not run on matches
shorter than this. (sapbert is less good at symbolic matching than string processing techniques)</p></li>
<li><p><strong>ignore_high_conf</strong> – If a perfect match has already been found, don’t run sapbert</p></li>
<li><p><strong>lookup_cache_size</strong> – the size of the Least Recently Used lookup cache to maintain</p></li>
<li><p><strong>top_n</strong> – keep up to the top_n hits of the query</p></li>
<li><p><strong>score_cutoffs</strong> – min score for a hit to be considered. first is lower bound for medium confidence,
second is upper bound for med high confidence</p></li>
<li><p><strong>batch_size</strong> – inference batch size</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="kazu.steps.DictionaryEntityLinkingStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">kazu.steps.</span></span><span class="sig-name descname"><span class="pre">DictionaryEntityLinkingStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apidocs.html#kazu.utils.link_index.DictionaryIndex" title="kazu.utils.link_index.DictionaryIndex"><span class="pre">DictionaryIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.DictionaryEntityLinkingStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses synonym lists to match entities to ontologies.</p>
<dl class="py method">
<dt class="sig sig-object py" id="kazu.steps.DictionaryEntityLinkingStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apidocs.html#kazu.utils.link_index.DictionaryIndex" title="kazu.utils.link_index.DictionaryIndex"><span class="pre">DictionaryIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#kazu.steps.DictionaryEntityLinkingStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>index_group</strong> – A CachedIndexGroup constructed with List[DictionaryIndexCacheManager]</p></li>
<li><p><strong>lookup_cache_size</strong> – the size of the Least Recently Used lookup cache to maintain</p></li>
<li><p><strong>top_n</strong> – keep the top_n hits of the query</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ensembling-linking-methods">
<h1>Ensembling linking methods<a class="headerlink" href="#ensembling-linking-methods" title="Permalink to this heading">¶</a></h1>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">String Preprocessing</a><ul>
<li><a class="reference internal" href="#current-implementations-of-stringpreprocessorstep">Current implementations of StringPreprocessorStep</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ner">NER</a></li>
<li><a class="reference internal" href="#linking">Linking</a></li>
<li><a class="reference internal" href="#ensembling-linking-methods">Ensembling linking methods</a></li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="datamodel.html"
                          title="previous chapter">Kazu data model</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="training.html"
                          title="next chapter">TBA</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/steps.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="training.html" title="TBA"
             >next</a> |</li>
        <li class="right" >
          <a href="datamodel.html" title="Kazu data model"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Kazu  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">String Preprocessing</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Korea University, AstraZeneca.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.0.2.
    </div>
  </body>
</html>