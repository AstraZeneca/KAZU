
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>String Preprocessing &#8212; Kazu  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="TBA" href="training.html" />
    <link rel="prev" title="Kazu data model" href="datamodel.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="training.html" title="TBA"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="datamodel.html" title="Kazu data model"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Kazu  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">String Preprocessing</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="string-preprocessing">
<h1>String Preprocessing<a class="headerlink" href="#string-preprocessing" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.StringPreprocessorStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">StringPreprocessorStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.StringPreprocessorStep" title="Permalink to this definition">¶</a></dt>
<dd><p>String Preprocessing steps (subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">azner.steps.string_preprocessing.StringPreprocessorStep</span></code> are a
special class of step that involves destructive string preprocessing. For instance, you may want to expand
abbreviations before running an NER step.</p>
<p>Implementations will modify the return value of <code class="xref py py-meth docutils literal notranslate"><span class="pre">azner.data.data.Section.get_text()</span></code>. The
idea is that implementations of these will perform any required string preprocessing before the section text is
passed to another <code class="xref py py-class docutils literal notranslate"><span class="pre">azner.steps.base.step.Step</span></code>.  Implementations of this step update the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">azner.data.data.Section.offset_map</span></code>, so that offsets for objects generated by subsequent steps can be
traced back to the original string.</p>
<p>simple implementations need only override create_modifications.</p>
</dd></dl>

<section id="current-implementations-of-stringpreprocessorstep">
<h2>Current implementations of StringPreprocessorStep<a class="headerlink" href="#current-implementations-of-stringpreprocessorstep" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.SciSpacyAbbreviationExpansionStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">SciSpacyAbbreviationExpansionStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.SciSpacyAbbreviationExpansionStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Detects abbreviations using the algorithm in “A simple algorithm for identifying
abbreviation definitions in biomedical text.”, (Schwartz &amp; Hearst, 2003).
Uses a modified version of the scispacy abbreviation finder rules, to expand abbreviations. In this implementation,
it’s possible to apply abbreviations across the multiple sections in a <code class="xref py py-class docutils literal notranslate"><span class="pre">azner.data.data.Document</span></code>.
For instance, abbreviations learnt in an abstract will also be applied throughout the body of the text</p>
</dd></dl>

</section>
</section>
<section id="ner">
<h1>NER<a class="headerlink" href="#ner" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">TransformersModelForTokenClassificationNerStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep" title="Permalink to this definition">¶</a></dt>
<dd><p>An wrapper for <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.AutoModelForTokenClassification'</span> <span class="pre">and</span>
<span class="pre">:class:`azner.steps.ner.bio_label_preprocessor.BioLabelPreProcessor</span></code>. This implementation uses a sliding
window concept to process large documents that don’t fit into the maximum sequence length allowed by a model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stride</strong> – passed to HF tokenizers (for splitting long docs)</p></li>
<li><p><strong>max_sequence_length</strong> – passed to HF tokenizers (for splitting long docs)</p></li>
<li><p><strong>path</strong> – path to HF model, config and tokenizer. Passed to HF .from_pretrained()</p></li>
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>batch_size</strong> – batch size for dataloader</p></li>
<li><p><strong>debug</strong> – print extra logging info</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.get_confidence_and_labels_tensor">
<span class="sig-name descname"><span class="pre">get_confidence_and_labels_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.dataloader.DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.get_confidence_and_labels_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>get a namedtuple_values_indices consisting of confidence and labels for a given dataloader (i.e. run bert)
:param loader:
:return:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.get_dataloader">
<span class="sig-name descname"><span class="pre">get_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">docs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">azner.data.data.Document</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.utils.data.dataloader.DataLoader</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">azner.data.data.Section</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.get_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>get a dataloader from a List of Document. Collation is handled via DataCollatorWithPadding</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>docs</strong> – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tuple of dataloader, and a dict of int:Section. The int maps to overflow_to_sample_mapping in the
underlying batch encoding, allowing the processing of docs longer than can fit within the maximum
sequence length of a transformer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.get_list_of_batch_encoding_frames_for_section">
<span class="sig-name descname"><span class="pre">get_list_of_batch_encoding_frames_for_section</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.tokenization_utils_base.BatchEncoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">section_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.get_list_of_batch_encoding_frames_for_section" title="Permalink to this definition">¶</a></dt>
<dd><p>for a given dataloader with a HFDataset, return a list of frame indexes associated with a given section index
:param loader:
:param section_index:
:return:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.get_offset_and_word_id_frames">
<span class="sig-name descname"><span class="pre">get_offset_and_word_id_frames</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.tokenization_utils_base.BatchEncoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_frames</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">section_frame_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_and_labels_tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.get_offset_and_word_id_frames" title="Permalink to this definition">¶</a></dt>
<dd><p>depending on the number of frames generated by a string of text, and whether it is the first or last frame,
we need to return different subsets of the frame offsets and frame word_ids
:param batch_encoding: a HF BatchEncoding
:param number_of_frames: number of frames created by the tokenizer for the string
:param frame_index: the index of the query frame, relative to the total number of frames
:param section_frame_index: the index of the section frame, relative to the whole BatchEncoding
:return: Tuple of 2 lists: frame offsets and frame word ids</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.TransformersModelForTokenClassificationNerStep.merge_section_frames">
<span class="sig-name descname"><span class="pre">merge_section_frames</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">section_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.tokenization_utils_base.BatchEncoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_and_labels_tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="apidocs.html#azner.data.data.NerProcessedSection" title="azner.data.data.NerProcessedSection"><span class="pre">azner.data.data.NerProcessedSection</span></a></span></span><a class="headerlink" href="#azner.steps.TransformersModelForTokenClassificationNerStep.merge_section_frames" title="Permalink to this definition">¶</a></dt>
<dd><p>for a given section index, obtain a NerProcessedSection representing all of the inferred labels for that section
:param section_index: int of the section index
:param batch_encoding: the BatchEncoding for this dataset
:param confidence_and_labels_tensor: a tuple of the confidence and labels from the model
:return:</p>
</dd></dl>

</dd></dl>

</section>
<section id="linking">
<h1>Linking<a class="headerlink" href="#linking" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">SapBertForEntityLinkingStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">azner.modelling.linking.sapbert.train.PLSapbertModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dl_workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_partition_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_index_factory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="apidocs.html#azner.utils.link_index.EmbeddingIndexFactory" title="azner.utils.link_index.EmbeddingIndexFactory"><span class="pre">azner.utils.link_index.EmbeddingIndexFactory</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_all_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rebuild_ontology_cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep" title="Permalink to this definition">¶</a></dt>
<dd><p>This step wraps Sapbert: Self Alignment pretraining for biomedical entity representation.
We make use of two caches here:
1) <a class="reference internal" href="apidocs.html#azner.utils.link_index.EmbeddingIndex" title="azner.utils.link_index.EmbeddingIndex"><code class="xref py py-class docutils literal notranslate"><span class="pre">azner.utils.link_index.EmbeddingIndex</span></code></a> Since these are static and numerous, it makes sense to
precompute them once and reload them each time. This is done automatically if no cache file is detected.
2) <a class="reference internal" href="apidocs.html#azner.utils.caching.EntityLinkingLookupCache" title="azner.utils.caching.EntityLinkingLookupCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">azner.utils.caching.EntityLinkingLookupCache</span></code></a> Since certain entities will come up more frequently, we
cache the result mappings rather than call bert repeatedly.</p>
<p>Original paper <a class="reference external" href="https://aclanthology.org/2021.naacl-main.334.pdf">https://aclanthology.org/2021.naacl-main.334.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">azner.modelling.linking.sapbert.train.PLSapbertModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pytorch_lightning.trainer.trainer.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dl_workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_partition_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_index_factory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="apidocs.html#azner.utils.link_index.EmbeddingIndexFactory" title="azner.utils.link_index.EmbeddingIndexFactory"><span class="pre">azner.utils.link_index.EmbeddingIndexFactory</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_all_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rebuild_ontology_cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depends_on</strong> – namespaces of dependency stes</p></li>
<li><p><strong>model</strong> – a pretrained Sapbert Model</p></li>
<li><p><strong>ontology_path</strong> – path to file to generate embeddings from. See <code class="xref py py-meth docutils literal notranslate"><span class="pre">azner.modelling.</span>
<span class="pre">ontology_preprocessing.base.OntologyParser.OntologyParser.write_default_labels()</span></code> for format</p></li>
<li><p><strong>batch_size</strong> – for inference with Pytorch</p></li>
<li><p><strong>trainer</strong> – a pytorch lightning Trainer to handle the inference for us</p></li>
<li><p><strong>dl_workers</strong> – number fo dataloader workers</p></li>
<li><p><strong>ontology_partition_size</strong> – when generating embeddings, process n in a partition before serialising to disk.
(reduce if memory is an issue)</p></li>
<li><p><strong>embedding_index_factory</strong> – For creating Embedding Indexes</p></li>
<li><p><strong>entity_class_to_ontology_mappings</strong> – A Dict[str,str] that maps an entity class to the Ontology it should be
processed against</p></li>
<li><p><strong>process_all_entities</strong> – if False, ignore entities that already have a mapping</p></li>
<li><p><strong>rebuild_ontology_cache</strong> – Force rebuild of embedding cache</p></li>
<li><p><strong>lookup_cache_size</strong> – size of lookup cache to maintain</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.cache_ontology_embeddings">
<span class="sig-name descname"><span class="pre">cache_ontology_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="apidocs.html#azner.utils.link_index.EmbeddingIndex" title="azner.utils.link_index.EmbeddingIndex"><span class="pre">azner.utils.link_index.EmbeddingIndex</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.cache_ontology_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>since the generation of the ontology embeddings is slow, we cache this to disk after this is done once.
:return: ontology_name:Index dict</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.get_embeddings_for_strings">
<span class="sig-name descname"><span class="pre">get_embeddings_for_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.get_embeddings_for_strings" title="Permalink to this definition">¶</a></dt>
<dd><p>for a list of strings, get the associated embeddings
:param texts:
:return: a 2d tensor of embeddings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.get_embeddings_from_dataloader">
<span class="sig-name descname"><span class="pre">get_embeddings_from_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.dataloader.DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.get_embeddings_from_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>get the cls token output from all data in a dataloader as a 2d tensor
:param loader:
:return: 2d tensor of cls  output</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.get_or_create_ontology_index_dict">
<span class="sig-name descname"><span class="pre">get_or_create_ontology_index_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.get_or_create_ontology_index_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>populate self.ontology_ids and self.ontology_index_dict either by calculating them afresh or loading from a
cached version on disk</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.load_ontology_index_dict_from_cache">
<span class="sig-name descname"><span class="pre">load_ontology_index_dict_from_cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="apidocs.html#azner.utils.link_index.EmbeddingIndex" title="azner.utils.link_index.EmbeddingIndex"><span class="pre">azner.utils.link_index.EmbeddingIndex</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.load_ontology_index_dict_from_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>loads the cached version of the embedding indices from disk
:return: ontology:Index dict</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.predict_ontology_embeddings">
<span class="sig-name descname"><span class="pre">predict_ontology_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ontology_dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.predict_ontology_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>based on the value of self.ontology_path, this returns a Tuple[List[str],np.ndarray]. The strings are the
iri’s, and the torch.Tensor are the embeddings to be queried against
:return: partition number, dataframe for metadata, 2d tensor of embeddings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.SapBertForEntityLinkingStep.split_dataframe">
<span class="sig-name descname"><span class="pre">split_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.SapBertForEntityLinkingStep.split_dataframe" title="Permalink to this definition">¶</a></dt>
<dd><p>generator to split up a dataframe into partitions
:param df:
:param chunk_size: size of partittions to create
:return:</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.DictionaryEntityLinkingStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">DictionaryEntityLinkingStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_dictionary_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="apidocs.html#azner.utils.link_index.DictionaryIndex" title="azner.utils.link_index.DictionaryIndex"><span class="pre">azner.utils.link_index.DictionaryIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_all_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.DictionaryEntityLinkingStep" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple dictionary lookup step, using RapidFuzz for string matching</p>
<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.DictionaryEntityLinkingStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_class_to_ontology_mappings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_dictionary_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="apidocs.html#azner.utils.link_index.DictionaryIndex" title="azner.utils.link_index.DictionaryIndex"><span class="pre">azner.utils.link_index.DictionaryIndex</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">process_all_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lookup_cache_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.DictionaryEntityLinkingStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>entity_class_to_ontology_mappings</strong> – Dict mapping entity class to ontology names</p></li>
<li><p><strong>ontology_dictionary_index</strong> – Dict of ontology name: DictionaryIndex</p></li>
<li><p><strong>process_all_entities</strong> – if false, will ignore any entities with mappings already associated</p></li>
<li><p><strong>lookup_cache_size</strong> – cache size to prevent repeated calls to the index</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ensembling-linking-methods">
<h1>Ensembling linking methods<a class="headerlink" href="#ensembling-linking-methods" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="azner.steps.EnsembleEntityLinkingStep">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">azner.steps.</span></span><span class="sig-name descname"><span class="pre">EnsembleEntityLinkingStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linker_score_thresholds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.EnsembleEntityLinkingStep" title="Permalink to this definition">¶</a></dt>
<dd><p>ensemble methods to use information from multiple linkers when choosing the ‘best’ mapping. See
<a class="reference internal" href="apidocs.html#azner.steps.linking.link_ensembling.MappingPostProcessing" title="azner.steps.linking.link_ensembling.MappingPostProcessing"><code class="xref py py-class docutils literal notranslate"><span class="pre">azner.steps.linking.link_ensembling.MappingPostProcessing</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="azner.steps.EnsembleEntityLinkingStep.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depends_on</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linker_score_thresholds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#azner.steps.EnsembleEntityLinkingStep.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depends_on</strong> – </p></li>
<li><p><strong>linker_score_thresholds</strong> – Dict that maps a linker namespace to it’s score threshold</p></li>
<li><p><strong>keep_top_n</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">String Preprocessing</a><ul>
<li><a class="reference internal" href="#current-implementations-of-stringpreprocessorstep">Current implementations of StringPreprocessorStep</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ner">NER</a></li>
<li><a class="reference internal" href="#linking">Linking</a></li>
<li><a class="reference internal" href="#ensembling-linking-methods">Ensembling linking methods</a></li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="datamodel.html"
                        title="previous chapter">Kazu data model</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="training.html"
                        title="next chapter">TBA</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/steps.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="training.html" title="TBA"
             >next</a> |</li>
        <li class="right" >
          <a href="datamodel.html" title="Kazu data model"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Kazu  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">String Preprocessing</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Korea University, AstraZeneca.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.1.
    </div>
  </body>
</html>